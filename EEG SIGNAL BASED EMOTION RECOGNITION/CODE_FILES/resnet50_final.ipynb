{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3n2w22OR_tos"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.signal import butter, lfilter\n",
        "import pywt\n",
        "\n",
        "# Load DEAP dataset\n",
        "def load_deap_data(data_dir):\n",
        "    eeg_data = []\n",
        "    labels = []\n",
        "\n",
        "    for file in os.listdir(data_dir):\n",
        "        if file.endswith('.dat'):\n",
        "            file_path = os.path.join(data_dir, file)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                subject_data = pickle.load(f, encoding='latin1')\n",
        "                eeg_data.append(subject_data['data'])\n",
        "                labels.append(subject_data['labels'])\n",
        "\n",
        "    eeg_data = np.concatenate(eeg_data, axis=0)\n",
        "    labels = np.concatenate(labels, axis=0)\n",
        "    return eeg_data, labels\n",
        "\n",
        "# Preprocess data: normalize, filter, and extract delta rhythm\n",
        "def preprocess_data(eeg_data, lowcut=0.5, highcut=4.0, fs=128, order=5):\n",
        "    def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "        nyquist = 0.5 * fs\n",
        "        low = lowcut / nyquist\n",
        "        high = highcut / nyquist\n",
        "        b, a = butter(order, [low, high], btype='band')\n",
        "        return b, a\n",
        "\n",
        "    def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "        y = lfilter(b, a, data)\n",
        "        return y\n",
        "\n",
        "    # Normalizing the data\n",
        "    eeg_data = eeg_data / np.max(np.abs(eeg_data), axis=(1, 2), keepdims=True)\n",
        "    filtered_data = []\n",
        "    for trial in eeg_data:\n",
        "        filtered_trial = np.array([bandpass_filter(channel, lowcut, highcut, fs, order) for channel in trial])\n",
        "        filtered_data.append(filtered_trial)\n",
        "    return np.array(filtered_data)\n",
        "\n",
        "# Convert EEG signals to images using Continuous Wavelet Transform (CWT)\n",
        "def eeg_to_cwt_images(eeg_data, scales, waveletname='morl'):\n",
        "    eeg_images = []\n",
        "    for trial in eeg_data:\n",
        "        trial_images = []\n",
        "        for channel in trial:\n",
        "            coeffs, _ = pywt.cwt(channel, scales, waveletname)\n",
        "            trial_images.append(coeffs)\n",
        "        # Stack the coefficient arrays to form a single image per trial\n",
        "        # To reduce the dimensions, we can either average or select key channels.\n",
        "        trial_images = np.stack(trial_images[:3], axis=-1)  # Stacking first 3 channels along the last dimension\n",
        "        eeg_images.append(trial_images)\n",
        "    return np.array(eeg_images)\n",
        "\n",
        "# Label the dataset into four classes based on valence and arousal\n",
        "def label_data(labels):\n",
        "    valence = labels[:, 0]\n",
        "    arousal = labels[:, 1]\n",
        "    combined_labels = []\n",
        "    for v, a in zip(valence, arousal):\n",
        "        if v >= 5 and a >= 5:\n",
        "            combined_labels.append('HVHA')\n",
        "        elif v >= 5 and a < 5:\n",
        "            combined_labels.append('HVLA')\n",
        "        elif v < 5 and a >= 5:\n",
        "            combined_labels.append('LVHA')\n",
        "        else:\n",
        "            combined_labels.append('LVLA')\n",
        "    return np.array(combined_labels)\n",
        "\n",
        "# Generator function to yield batches of data\n",
        "def data_generator(eeg_data, labels, scales, batch_size):\n",
        "    num_samples = eeg_data.shape[0]\n",
        "    while True:\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            batch_data = eeg_data[offset:offset + batch_size]\n",
        "            batch_labels = labels[offset:offset + batch_size]\n",
        "            batch_images = eeg_to_cwt_images(batch_data, scales)\n",
        "\n",
        "            # Debugging: Check the shape of the generated CWT images\n",
        "            assert len(batch_images.shape) == 4, f\"batch_images should have 4 dimensions (batch_size, height, width, channels). Got {batch_images.shape}\"\n",
        "\n",
        "            # Resize images for MobileNetV2 and replicate channels\n",
        "            batch_images_resized = np.array([tf.image.resize(img, (224, 224)).numpy() for img in batch_images])\n",
        "\n",
        "            # Ensure the resized images have the correct shape\n",
        "            assert len(batch_images_resized.shape) == 4, f\"batch_images_resized should have 4 dimensions (batch_size, 224, 224, channels). Got {batch_images_resized.shape}\"\n",
        "\n",
        "            # Replicate the grayscale image across 3 channels if needed\n",
        "            if batch_images_resized.shape[-1] != 3:\n",
        "                batch_images_rgb = np.repeat(batch_images_resized[..., np.newaxis], 3, axis=-1)\n",
        "            else:\n",
        "                batch_images_rgb = batch_images_resized\n",
        "\n",
        "            yield batch_images_rgb, batch_labels\n",
        "\n",
        "# Load and preprocess the data\n",
        "data_dir = '/content/drive/My Drive/data_preprocessed_python'  # Update this path to your dataset in Google Drive\n",
        "eeg_data, labels = load_deap_data(data_dir)\n",
        "eeg_data = preprocess_data(eeg_data)\n",
        "scales = np.arange(1, 129)\n",
        "\n",
        "# Label the dataset\n",
        "combined_labels = label_data(labels)\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(combined_labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(eeg_data, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC6vW3oE_zIb",
        "outputId": "b3b9c530-e216-4f4a-b1bd-7c1a287c613a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Epoch 1/8\n",
            "128/128 [==============================] - 6699s 53s/step - loss: 1.6386 - accuracy: 0.2402 - val_loss: 1.4007 - val_accuracy: 0.3359\n",
            "Epoch 2/8\n",
            "128/128 [==============================] - 6657s 52s/step - loss: 1.4241 - accuracy: 0.2559 - val_loss: 1.4044 - val_accuracy: 0.3316\n",
            "Epoch 3/8\n",
            "128/128 [==============================] - 6764s 53s/step - loss: 1.4022 - accuracy: 0.3105 - val_loss: 1.3975 - val_accuracy: 0.3382\n",
            "Epoch 4/8\n",
            "128/128 [==============================] - 7022s 55s/step - loss: 1.3972 - accuracy: 0.3105 - val_loss: 1.3924 - val_accuracy: 0.3401\n",
            "Epoch 5/8\n",
            "128/128 [==============================] - 7477s 59s/step - loss: 1.3935 - accuracy: 0.3116 - val_loss: 1.3884 - val_accuracy: 0.3489\n",
            "Epoch 6/8\n",
            "128/128 [==============================] - 7204s 56s/step - loss: 1.3925 - accuracy: 0.3238 - val_loss: 1.3677 - val_accuracy: 0.3546\n",
            "Epoch 7/8\n",
            "128/128 [==============================] - 7264s 57s/step - loss: 1.3891 - accuracy: 0.3445 - val_loss: 1.3598 - val_accuracy: 0.3623\n",
            "Epoch 8/8\n",
            "128/128 [==============================] - 7477s 59s/step - loss: 1.3712 - accuracy: 0.3696 - val_loss: 1.3450 - val_accuracy: 0.3718\n",
            "Epoch 1/4\n",
            "128/128 [==============================] - 9818s 77s/step - loss: 1.3700 - accuracy: 0.3722 - val_loss: 1.3323 - val_accuracy: 0.3834\n",
            "Epoch 2/4\n",
            "128/128 [==============================] – 10,693s 84s/step - loss: 1.3646 - accuracy: 0.3856 - val_loss: 1.3289 - val_accuracy: 0.3915\n",
            "Epoch 3/4\n",
            "128/128 [==============================] – 10,774s 84s/step - loss: 1.3598 - accuracy: 0.3999 - val_loss: 1.3156 - val_accuracy: 0.4145\n",
            "Epoch 4/4\n",
            "128/128 [==============================] - 9897s 78s/step - loss: 1.3412 - accuracy: 0.4234 - val_loss: 1.3097 - val_accuracy: 0.4193\n",
            "Accuracy: 0.3979\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Load ResNet50 model pre-trained on ImageNet\n",
        "base_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the data generator\n",
        "batch_size = 4\n",
        "train_generator = data_generator(X_train, y_train, scales, batch_size, augment_fn=data_augmentation)\n",
        "test_generator = data_generator(X_test, y_test, scales, batch_size)\n",
        "val_generator = data_generator(X_val, y_val, scales, batch_size)\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "steps_per_epoch = len(X_train) // batch_size\n",
        "validation_steps = len(X_test) // batch_size\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(train_generator, epochs=8, steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=val_generator, validation_steps=validation_steps, callbacks=[early_stopping])\n",
        "\n",
        "# Fine-tune the model\n",
        "base_model.trainable = True\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history_finetune = model.fit(train_generator, epochs=4, steps_per_epoch=steps_per_epoch,\n",
        "                             validation_data=val_generator, validation_steps=validation_steps, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = model.evaluate(test_generator, steps=len(X_test) // batch_size)\n",
        "print(\"Accuracy:\", test_accuracy)\n",
        "\n",
        "\n",
        "# Print epochs and train/validation accuracy and loss\n",
        "def print_epoch_metrics(history, history_finetune=None):\n",
        "    print(\"Epoch\\tTrain Loss\\tTrain Accuracy\\tValidation Loss\\tValidation Accuracy\")\n",
        "    for i in range(len(history.history['loss'])):\n",
        "        print(f\"{i+1}\\t{history.history['loss'][i]:.4f}\\t\\t{history.history['accuracy'][i]:.4f}\\t\\t{history.history['val_loss'][i]:.4f}\\t\\t{history.history['val_accuracy'][i]:.4f}\")\n",
        "    if history_finetune:\n",
        "        for i in range(len(history_finetune.history['loss'])):\n",
        "            print(f\"{i+1 + len(history.history['loss'])}\\t{history_finetune.history['loss'][i]:.4f}\\t\\t{history_finetune.history['accuracy'][i]:.4f}\\t\\t{history_finetune.history['val_loss'][i]:.4f}\\t\\t{history_finetune.history['val_accuracy'][i]:.4f}\")\n",
        "\n",
        "print_epoch_metrics(history, history_finetune)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
